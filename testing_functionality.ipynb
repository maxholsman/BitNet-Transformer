{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absmax_quantization(x, bit=8):\n",
    "    Qb = 2**(bit - 1)\n",
    "    # find the maximum absolute value in the tensor\n",
    "    max_val = torch.max(torch.abs(x))\n",
    "    # using the max values, we can calculate the scaling factor for each value in the tensor to map it to the range appropriate range\n",
    "    scale_factor = Qb / max_val\n",
    "    # now we can quantize the tensor, rounding to the nearest integer\n",
    "    x = torch.round(x * scale_factor)\n",
    "    # x = (x * scale_factor).round()\n",
    "    return x.to(torch.int8), max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absmax_dequantization(x, max_val, bit=8):\n",
    "    Qb = 2**(bit - 1)\n",
    "    \n",
    "    reverse_scale_factor = max_val / Qb\n",
    "    \n",
    "    x = x * reverse_scale_factor\n",
    "    \n",
    "    return x.to(torch.float32) # return to float32 which is original precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[-0.8894, -0.5349,  0.6481,  0.3875,  0.0349, -1.7664,  0.5548, -0.4214,\n",
      "          1.7691,  0.0169,  0.3873,  0.8700,  0.1457,  0.5463, -0.9343, -0.4479,\n",
      "          1.4549, -0.9986,  2.8610,  0.6735, -0.0676,  0.2125, -0.1026, -0.6561,\n",
      "          0.0320]])\n",
      "output: tensor([[ -40,  -24,   29,   17,    2,  -79,   25,  -19,   79,    1,   17,   39,\n",
      "            7,   24,  -42,  -20,   65,  -45, -128,   30,   -3,   10,   -5,  -29,\n",
      "            1]], dtype=torch.int8)\n",
      "output dtype: torch.int8\n",
      "dequant output: tensor([[-0.8941, -0.5364,  0.6482,  0.3800,  0.0447, -1.7658,  0.5588, -0.4247,\n",
      "          1.7658,  0.0224,  0.3800,  0.8717,  0.1565,  0.5364, -0.9388, -0.4470,\n",
      "          1.4528, -1.0058, -2.8610,  0.6705, -0.0671,  0.2235, -0.1118, -0.6482,\n",
      "          0.0224]])\n",
      "dequant output dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 25)\n",
    "print(f\"input: {input}\")\n",
    "output, max_val = absmax_quantization(input)\n",
    "print(f\"output: {output}\")\n",
    "print(f\"output dtype: {output.dtype}\")\n",
    "\n",
    "dequant_output = absmax_dequantization(output, max_val)\n",
    "print(f\"dequant output: {dequant_output}\")\n",
    "print(f\"dequant output dtype: {dequant_output.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, groups=1, bit=8, nl_next=False, bias=True):\n",
    "        super(BitLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.groups = groups\n",
    "        print(f\"input: {in_features}, output: {out_features}, groups: {groups}\")\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.Tensor(self.out_features, self.in_features))\n",
    "        \n",
    "        print(f\"weights: {self.weights.shape}\")\n",
    "        # Upon initialization, the weights will be randomly initialized using the kaiming uniform method\n",
    "        self.parameter_initialization()\n",
    "        \n",
    "    def parameter_initialization(self):\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        weights = self.weights.view(self.groups, -1, self.in_features)\n",
    "        \n",
    "        # normalize to zero mean\n",
    "        weights = weights - weights.mean(dim=[1, 2], keepdim=True)\n",
    "        \n",
    "        # quantize weights\n",
    "        weights = torch.sign(weights)\n",
    "        \n",
    "        # calculate beta as 1-norm of weights divided by n*m\n",
    "        beta = (torch.norm(weights, p=1, dim=[1, 2], keepdim=True) / \n",
    "                              (weights.shape[1] * weights.shape[2]))\n",
    "        \n",
    "        #scale the weights by beta\n",
    "        weights = weights * beta\n",
    "        \n",
    "        #reshape to original shape\n",
    "        weights = weights.view(self.out_features, self.in_features)\n",
    "        \n",
    "        # get quantized inputs\n",
    "        quantized_input, gamma = absmax_quantization(x)\n",
    "        \n",
    "        # forward pass\n",
    "        print(f\"weights: {weights}\")\n",
    "        print(f\"quantized input: {quantized_input}\")\n",
    "        output = torch.matmul(quantized_input.float(), weights.t())\n",
    "        \n",
    "        print(f\"output: {output}\")\n",
    "        output = absmax_dequantization(output, gamma)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[-1.0619, -0.2755,  0.9684,  1.3968,  1.9292,  0.2815, -0.9012,  0.8763,\n",
      "         -0.5202, -0.5438,  0.1914, -1.1180,  1.4784, -1.0089, -0.1801, -3.5963,\n",
      "         -0.5111,  0.5066,  0.9411,  1.2713,  1.6487, -0.1585, -1.4995,  0.9017,\n",
      "          1.5501]])\n",
      "input: 25, output: 10, groups: 1\n",
      "weights: torch.Size([10, 25])\n",
      "weights: tensor([[ 1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
      "          1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.],\n",
      "        [ 1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
      "          1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.],\n",
      "        [-1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
      "          1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.],\n",
      "        [ 1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
      "         -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.],\n",
      "        [-1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,\n",
      "         -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
      "         -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.],\n",
      "        [ 1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.],\n",
      "        [ 1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
      "         -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.],\n",
      "        [-1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "quantized input: tensor([[ -38,  -10,   34,   50,   69,   10,  -32,   31,  -19,  -19,    7,  -40,\n",
      "           53,  -36,   -6, -128,  -18,   18,   33,   45,   59,   -6,  -53,   32,\n",
      "           55]], dtype=torch.int8)\n",
      "output: tensor([[ -37., -179., -231., -233., -293.,  213.,   67., -471., -305.,   85.]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "output: tensor([[ -1.0396,  -5.0292,  -6.4902,  -6.5464,  -8.2322,   5.9845,   1.8824,\n",
      "         -13.2333,  -8.5693,   2.3882]], grad_fn=<MulBackward0>)\n",
      "output dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 25)\n",
    "print(f\"input: {input}\")\n",
    "bitlinear = BitLinear(25, 10)\n",
    "output = bitlinear(input)\n",
    "print(f\"output: {output}\")\n",
    "print(f\"output dtype: {output.dtype}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
