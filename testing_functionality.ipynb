{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD\n",
    "def absmax_quantization(x, bit=8):\n",
    "    Qb = 2**(bit - 1)\n",
    "    \n",
    "    # find the maximum absolute value in the tensor\n",
    "    max_val = torch.max(torch.abs(x))\n",
    "    \n",
    "    # using the max values, we can calculate the scaling factor for each value in the tensor to map it to the range appropriate range\n",
    "    scale_factor = Qb / max_val\n",
    "    \n",
    "    # now we can quantize the tensor, rounding to the nearest integer\n",
    "    x = torch.round(x * scale_factor)\n",
    "    \n",
    "    return x.to(torch.int8), max_val\n",
    "\n",
    "def absmax_dequantization(x, max_val, bit=8):\n",
    "    Qb = 2**(bit - 1)\n",
    "    \n",
    "    reverse_scale_factor = max_val / Qb\n",
    "    \n",
    "    x = x * reverse_scale_factor\n",
    "    \n",
    "    return x.to(torch.float32) # return to float32 which is original precision\n",
    "\n",
    "class BitLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, groups=1, bit=8, nl_next=False, bias=True):\n",
    "        super(BitLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.groups = groups\n",
    "        # print(f\"input: {in_features}, output: {out_features}, groups: {groups}\")\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.Tensor(self.out_features, self.in_features))\n",
    "        \n",
    "        # print(f\"weights: {self.weights.shape}\")\n",
    "        # Upon initialization, the weights will be randomly initialized using the kaiming uniform method\n",
    "        self.parameter_initialization()\n",
    "        \n",
    "    def parameter_initialization(self):\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        weights = self.weights.view(self.groups, -1, self.in_features)\n",
    "        \n",
    "        # normalize to zero mean\n",
    "        weights = weights - weights.mean(dim=[1, 2], keepdim=True)\n",
    "        \n",
    "        # quantize weights\n",
    "        weights = torch.sign(weights)\n",
    "        \n",
    "        # calculate beta as 1-norm of weights divided by n*m\n",
    "        beta = (torch.norm(weights, p=1, dim=[1, 2], keepdim=True) / \n",
    "                              (weights.shape[1] * weights.shape[2]))\n",
    "        \n",
    "        #scale the weights by beta\n",
    "        weights = weights * beta\n",
    "        \n",
    "        #reshape to original shape\n",
    "        weights = weights.view(self.out_features, self.in_features)\n",
    "        \n",
    "        # get quantized inputs\n",
    "        quantized_input, gamma = absmax_quantization(x)\n",
    "        \n",
    "        # forward pass\n",
    "        # print(f\"weights: {weights}\")\n",
    "        # print(f\"quantized input: {quantized_input}\")\n",
    "        output = torch.matmul(quantized_input.float(), weights.t())\n",
    "        \n",
    "        # print(f\"output: {output}\")\n",
    "        output = absmax_dequantization(output, gamma)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absmax_quantization(x, bit=8, nl_next=False):\n",
    "    Qb = 2**(bit - 1)\n",
    "    \n",
    "    # find the maximum absolute value in the tensor\n",
    "    max_val = torch.max(torch.abs(x))\n",
    "    min_val = torch.min(x)\n",
    "    \n",
    "    print(f\"data type before quantization: {x.type()}\")\n",
    "    \n",
    "    if nl_next:\n",
    "        shifted_x = x - min_val\n",
    "        max_val = torch.max(torch.abs(shifted_x))\n",
    "        \n",
    "        scale_factor = Qb / max_val\n",
    "        x = torch.round(shifted_x * scale_factor)\n",
    "    else:\n",
    "        # using the max values, we can calculate the scaling factor for each value in the tensor to map it to the range appropriate range\n",
    "        scale_factor = Qb / max_val\n",
    "        \n",
    "        # now we can quantize the tensor, rounding to the nearest integer\n",
    "        x = torch.round(x * scale_factor)\n",
    "    \n",
    "    dequant = max_val / Qb\n",
    "    \n",
    "    return x.to(torch.int8), dequant, max_val, min_val\n",
    "\n",
    "def absmax_dequantization(x, max_val, nl_next=False, min_val=None, bit=8):\n",
    "    Qb = 2**(bit - 1)\n",
    "    \n",
    "    reverse_scale_factor = max_val / Qb\n",
    "    \n",
    "    x = x * reverse_scale_factor\n",
    "    \n",
    "    return x.to(torch.float32) # return to float32 which is original precision\n",
    "\n",
    "class BitLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, groups=1, bit=8, nl_next=False, bias=True):\n",
    "        super(BitLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.groups = groups\n",
    "        self.nl_next = nl_next\n",
    "        \n",
    "        if bias is True:\n",
    "            self.bias = nn.Parameter(torch.randn(self.out_features))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.randn(self.out_features, self.in_features))\n",
    "        \n",
    "        # # print(f\"weights: {self.weights.shape}\")\n",
    "        # # Upon initialization, the weights will be randomly initialized using the kaiming uniform method\n",
    "        # self.parameter_initialization()\n",
    "        \n",
    "    # def parameter_initialization(self):\n",
    "    #     nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        input_norm = F.layer_norm(x, (self.in_features,))\n",
    "        \n",
    "        input_quant, dequant, gamma, eta = absmax_quantization(input_norm, nl_next=self.nl_next)\n",
    "        \n",
    "        print(f\"data type after quantization: {input_quant.type()}\")\n",
    "        \n",
    "        weight_quant = torch.sign(self.weights)\n",
    "        \n",
    "        print(f\"weight quant: {weight_quant}\")\n",
    "        \n",
    "        output = torch.matmul(input_quant.float(), weight_quant.t())\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            output = output + self.bias.unsqueeze(0).expand_as(output)\n",
    "            \n",
    "        beta = torch.norm(self.weights, p=1) / (self.in_features * self.out_features)\n",
    "        \n",
    "        output = output * dequant * beta\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 953.1671,  -93.2529, -873.9128,  526.3042,  212.9384,  716.6527,\n",
      "          397.1938, -655.5541, -177.6257,  196.9402,  722.6052,   18.9512,\n",
      "         -131.3445,  375.2721,  221.9041, -706.2743]])\n",
      "data type before quantization: torch.FloatTensor\n",
      "output: tensor([[ 127,  -13, -117,   71,   29,   96,   53,  -88,  -24,   26,   97,    3,\n",
      "          -18,   50,   30,  -95]], dtype=torch.int8), torch.CharTensor\n",
      "recon_input: tensor([[ 945.7205,  -96.8060, -871.2543,  528.7099,  215.9519,  714.8754,\n",
      "          394.6707, -655.3024, -178.7188,  193.6121,  722.3220,   22.3399,\n",
      "         -134.0391,  372.3309,  223.3985, -707.4287]]), torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# make a test input of values ranging from -1000 to 1000\n",
    "input = torch.rand(1, 16) * 2000 - 1000\n",
    "print(f\"x: {input}\")\n",
    "output, dequant, max_val, min_val = absmax_quantization(input)\n",
    "print(f\"output: {output}, {output.type()}\")\n",
    "recon_input = dequant * output\n",
    "print(f\"recon_input: {recon_input}, {recon_input.type()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type before quantization: torch.FloatTensor\n",
      "data type after quantization: torch.CharTensor\n",
      "weight quant: tensor([[ 1.,  1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,\n",
      "          1., -1.],\n",
      "        [-1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,\n",
      "          1., -1.],\n",
      "        [ 1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
      "         -1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "          1., -1.],\n",
      "        [-1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n",
      "         -1., -1.],\n",
      "        [ 1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
      "         -1., -1.],\n",
      "        [ 1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
      "         -1., -1.],\n",
      "        [ 1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
      "         -1., -1.],\n",
      "        [-1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
      "         -1., -1.],\n",
      "        [-1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
      "         -1., -1.],\n",
      "        [ 1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
      "         -1., -1.],\n",
      "        [ 1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
      "         -1., -1.],\n",
      "        [ 1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
      "          1.,  1.],\n",
      "        [-1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
      "         -1.,  1.],\n",
      "        [-1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.,\n",
      "         -1., -1.],\n",
      "        [-1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
      "          1., -1.]], grad_fn=<SignBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8729,  1.8419, -4.7915, -1.7068, -4.7331,  0.8427,  3.0279, -3.6637,\n",
       "          2.5646,  6.4944,  5.7991,  1.8301,  0.7808, -5.5449,  5.2603,  2.9647]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_layer = BitLinear(16, 16, bit=8)\n",
    "test_layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
